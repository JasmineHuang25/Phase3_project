{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance claim prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "The large size of the original datasets will fail to upload to GitHub later.  Therefore, data preprocessing has been performed in a separated notebook, and the cleaned DataFrame is saved as 'df.csv' ready for use.\n",
    "\n",
    "### 3 original datasets:\n",
    "- Traffic Crashes - Crashes\n",
    "- Traffic Crashes - Vehicles\n",
    "- Traffic Crashes - People\n",
    "\n",
    "### Preview and inspecting all 3 datasets:\n",
    "- Inspecting the datasets.\n",
    "- Based on project assumptions, adjust the DataFrames:\n",
    "    - From df_crash, select ‘INJURIES_TOTAL’ = ‘0’\n",
    "    - From df_people, select ‘PERSON_TYPE’ = ‘DRIVER’\n",
    "    - From df_vehicle, select ‘UNIT_TYPE’ = ‘DRIVER’\n",
    "    - From df_vehicle, select ‘VEHICLE_USE’ = ‘PERSONAL’\n",
    "\n",
    "- Explore each column and decide what to keep.\n",
    "- Merge all 3 DataFrames on column 'CRASH_RECORD_ID' and drop all null.\n",
    "- Convert column 'AGE' and 'VEHICLE_YEAR' Dtype from float64 to int for for smaller data size.\n",
    "- Save the cleaned DataFrame as 'df.csv'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and load the cleaned DataFarame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T08:19:31.362915Z",
     "start_time": "2022-12-30T08:19:30.400281Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer,  make_column_selector as selector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score,\\\n",
    "    accuracy_score, precision_score, f1_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T08:19:50.144246Z",
     "start_time": "2022-12-30T08:19:49.417379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DAMAGE</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>LIC_PLATE_STATE</th>\n",
       "      <th>VEHICLE_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>OVER $1,500</td>\n",
       "      <td>60634</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>TOYOTA MOTOR COMPANY, LTD.</td>\n",
       "      <td>4RUNNER</td>\n",
       "      <td>IL</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OVER $1,500</td>\n",
       "      <td>60634</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>TOYOTA MOTOR COMPANY, LTD.</td>\n",
       "      <td>CAMRY</td>\n",
       "      <td>IL</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>OVER $1,500</td>\n",
       "      <td>60625</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>TOYOTA MOTOR COMPANY, LTD.</td>\n",
       "      <td>4RUNNER</td>\n",
       "      <td>IL</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>OVER $1,500</td>\n",
       "      <td>60625</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>TOYOTA MOTOR COMPANY, LTD.</td>\n",
       "      <td>CAMRY</td>\n",
       "      <td>IL</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>$501 - $1,500</td>\n",
       "      <td>60620</td>\n",
       "      <td>F</td>\n",
       "      <td>40</td>\n",
       "      <td>NISSAN</td>\n",
       "      <td>ALTIMA</td>\n",
       "      <td>IL</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         DAMAGE ZIPCODE SEX  AGE                        MAKE  \\\n",
       "0           0    OVER $1,500   60634   F   39  TOYOTA MOTOR COMPANY, LTD.   \n",
       "1           1    OVER $1,500   60634   F   39  TOYOTA MOTOR COMPANY, LTD.   \n",
       "2           2    OVER $1,500   60625   M   32  TOYOTA MOTOR COMPANY, LTD.   \n",
       "3           3    OVER $1,500   60625   M   32  TOYOTA MOTOR COMPANY, LTD.   \n",
       "4           6  $501 - $1,500   60620   F   40                      NISSAN   \n",
       "\n",
       "     MODEL LIC_PLATE_STATE  VEHICLE_YEAR  \n",
       "0  4RUNNER              IL          2002  \n",
       "1    CAMRY              IL          2014  \n",
       "2  4RUNNER              IL          2002  \n",
       "3    CAMRY              IL          2014  \n",
       "4   ALTIMA              IL          2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T08:19:52.036942Z",
     "start_time": "2022-12-30T08:19:51.807450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 890082 entries, 0 to 890081\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   DAMAGE           890082 non-null  object\n",
      " 1   ZIPCODE          890082 non-null  object\n",
      " 2   SEX              890082 non-null  object\n",
      " 3   AGE              890082 non-null  int64 \n",
      " 4   MAKE             890082 non-null  object\n",
      " 5   MODEL            890082 non-null  object\n",
      " 6   LIC_PLATE_STATE  890082 non-null  object\n",
      " 7   VEHICLE_YEAR     890082 non-null  int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 54.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define X and y, perform train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T06:58:45.460829Z",
     "start_time": "2022-12-30T06:58:45.196775Z"
    }
   },
   "outputs": [],
   "source": [
    "# define X and y:\n",
    "\n",
    "X = df.drop('DAMAGE', axis=1)\n",
    "y = df['DAMAGE']\n",
    "\n",
    "# train_test_split:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pipeline and FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T06:59:58.484426Z",
     "start_time": "2022-12-30T06:59:58.468001Z"
    }
   },
   "outputs": [],
   "source": [
    "def grab_numeric(df):\n",
    "    return df.select_dtypes(include=['float', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T06:59:59.588135Z",
     "start_time": "2022-12-30T06:59:59.572151Z"
    }
   },
   "outputs": [],
   "source": [
    "# The FunctionTransformer will turn my function into a transformer:\n",
    "\n",
    "GrabNumeric = FunctionTransformer(grab_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:00:00.596577Z",
     "start_time": "2022-12-30T07:00:00.578570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pipe:\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('num', GrabNumeric),\n",
    "    ('ss', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:00:01.880666Z",
     "start_time": "2022-12-30T07:00:01.825922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7015679 , -0.02456622],\n",
       "       [-0.80864483,  0.07290066],\n",
       "       [ 0.44986578, -0.10578863],\n",
       "       ...,\n",
       "       [-0.80864483, -0.0408107 ],\n",
       "       [ 1.45667426, -0.12203311],\n",
       "       [ 1.07912108, -0.10578863]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the resualt:\n",
    "\n",
    "pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pipeline and ColumnTransformer\n",
    "\n",
    "\n",
    "#### We'll throw these mini-pipelines into our ColumnTransformer: numeric and categorical\n",
    "\n",
    "- numbers (AGE, VEHICLE_YEAR)\n",
    " - scale, impute\n",
    "\n",
    "- categorical (all other columuns)\n",
    " - OHE, impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:00:33.309403Z",
     "start_time": "2022-12-30T07:00:33.292131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numeric pipeline:\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('num_impute', SimpleImputer(strategy='mean')),\n",
    "    ('ss', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:00:33.895049Z",
     "start_time": "2022-12-30T07:00:33.882506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Categorical pipeline:\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('cat_impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector and ColumnTransformer\n",
    "This will return a callable list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:00:41.312651Z",
     "start_time": "2022-12-30T07:00:41.294051Z"
    }
   },
   "outputs": [],
   "source": [
    "# The \"remainder='passthrough\" tells the compiler to leave the other df columns unchanged.\n",
    "# The `ColumnTransformer` will take care of our preprocessing, so now we can add our model at the end of the pipeline:\n",
    "\n",
    "CT = ColumnTransformer(transformers=[\n",
    "    ('num_trans', num_pipe, selector(dtype_include='int64')),\n",
    "    ('cat_trans', cat_pipe, selector(dtype_include=object))\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:00:55.878730Z",
     "start_time": "2022-12-30T07:00:55.869107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGE', 'VEHICLE_YEAR']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing Selector:\n",
    "\n",
    "test = selector(dtype_include='int64')\n",
    "test(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing in Our Modeling Class from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:01:02.417680Z",
     "start_time": "2022-12-30T07:01:02.403427Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelWithCV():\n",
    "    '''Structure to save the model and more easily see its crossvalidation'''\n",
    "    \n",
    "    def __init__(self, model, model_name, X, y, cv_now=True):\n",
    "        self.model = model\n",
    "        self.name = model_name\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # For CV results\n",
    "        self.cv_results = None\n",
    "        self.cv_mean = None\n",
    "        self.cv_median = None\n",
    "        self.cv_std = None\n",
    "        #\n",
    "        if cv_now:\n",
    "            self.cross_validate()\n",
    "        \n",
    "    def cross_validate(self, X=None, y=None, kfolds=10):\n",
    "        '''\n",
    "        Perform cross-validation and return results.\n",
    "        \n",
    "        Args: \n",
    "          X:\n",
    "            Optional; Training data to perform CV on. Otherwise use X from object\n",
    "          y:\n",
    "            Optional; Training data to perform CV on. Otherwise use y from object\n",
    "          kfolds:\n",
    "            Optional; Number of folds for CV (default is 10)  \n",
    "        '''\n",
    "        \n",
    "        cv_X = X if X else self.X\n",
    "        cv_y = y if y else self.y\n",
    "\n",
    "        self.cv_results = cross_val_score(self.model, cv_X, cv_y, cv=kfolds)\n",
    "        self.cv_mean = np.mean(self.cv_results)\n",
    "        self.cv_median = np.median(self.cv_results)\n",
    "        self.cv_std = np.std(self.cv_results)\n",
    "\n",
    "        \n",
    "    def print_cv_summary(self):\n",
    "        cv_summary = (\n",
    "        f'''CV Results for `{self.name}` model:\n",
    "            {self.cv_mean:.5f} ± {self.cv_std:.5f} accuracy\n",
    "        ''')\n",
    "        print(cv_summary)\n",
    "\n",
    "        \n",
    "    def plot_cv(self, ax):\n",
    "        '''\n",
    "        Plot the cross-validation values using the array of results and given \n",
    "        Axis for plotting.\n",
    "        '''\n",
    "        ax.set_title(f'CV Results for `{self.name}` Model')\n",
    "        \n",
    "        # Thinner violinplot with higher bw\n",
    "        sns.violinplot(y=self.cv_results, ax=ax, bw=.4)\n",
    "        sns.swarmplot(\n",
    "                y=self.cv_results,\n",
    "                color='orange',\n",
    "                size=10,\n",
    "                alpha= 0.8,\n",
    "                ax=ax\n",
    "        )\n",
    "\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy/Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:01:05.598751Z",
     "start_time": "2022-12-30T07:01:05.579828Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_model = Pipeline([\n",
    "    ('ct', CT),\n",
    "    ('dummy', DummyClassifier(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-30T07:01:14.833057Z",
     "start_time": "2022-12-30T07:01:14.724007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('num_trans',\n",
       "                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x0000016ED21D1460>),\n",
       "                                                 ('cat_trans',\n",
       "                                                  Pipeline(steps=[('cat_impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x0000016ED21D15B0>)])),\n",
       "                ('dummy', DummyClassifier(strategy='most_frequent'))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-30T07:01:15.945Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 531, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 458, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1051, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 376, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 410, in fit_transform\n",
      "    return super().fit_transform(X, y)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 469, in transform\n",
      "    return out.toarray()\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\scipy\\sparse\\compressed.py\", line 1025, in toarray\n",
      "    out = self._process_toarray_args(order, out)\n",
      "  File \"C:\\Users\\Chiafeng\\anaconda3\\envs\\learn-env\\lib\\site-packages\\scipy\\sparse\\base.py\", line 1185, in _process_toarray_args\n",
      "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
      "MemoryError: Unable to allocate 44.2 GiB for an array with shape (600804, 9870) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "# Use the class without dummy pipe:\n",
    "\n",
    "dummy_model_pipe =  ModelWithCV(dummy_model, model_name='dummy', X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-30T05:44:12.757Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_model_pipe.print_cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-30T00:30:13.990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create FSM (First Simple Model)\n",
    "\n",
    "# logreg_fsm = Pipeline([\n",
    "#     ('ct',CT),\n",
    "#     ('logreg_fsm',LogisticRegression(random_state=42))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-30T00:30:13.991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the class with out logreg pipe\n",
    "# fsm_model_pipe =  ModelWithCV(logreg_fsm, model_name='fsm',X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-30T00:30:13.991Z"
    }
   },
   "outputs": [],
   "source": [
    "# fsm_model_pipe.print_cv_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
